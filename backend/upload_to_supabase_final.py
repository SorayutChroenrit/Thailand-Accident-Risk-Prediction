#!/usr/bin/env python3
"""
Upload CSV data to Supabase with correct schema mapping
"""

from datetime import datetime

import pandas as pd
from supabase_traffic_client import get_supabase_traffic_client

print("=" * 80)
print("üì§ UPLOAD CSV TO SUPABASE (FINAL VERSION)")
print("=" * 80)

# Load CSV
print("\nüìÅ Loading CSV...")
df = pd.read_csv("data/accident_2019_2025_with_weather.csv")
print(f"‚úÖ Loaded {len(df):,} records")

# Map CSV columns to Supabase schema
print("\nüîß Mapping columns to Supabase schema...")
column_mapping = {
    # Core accident info
    "ACC_CODE": "acc_code",
    "‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏": "accident_year",
    "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏": "accident_date",
    "‡πÄ‡∏ß‡∏•‡∏≤": "accident_time",
    "timestamp": "accident_datetime",
    "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô": "report_date",
    "‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô": "report_time",
    "hour": "hour",
    # Location
    "LATITUDE": "latitude",
    "LONGITUDE": "longitude",
    "‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î": "province",
    "KM": "km",
    "‡∏ö‡∏£‡∏¥‡πÄ‡∏ß‡∏ì‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏": "accident_location",
    # Organization/Route
    "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "organization",
    "‡∏™‡∏≤‡∏¢‡∏ó‡∏≤‡∏á‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô": "organization_route",
    "‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏¢‡∏ó‡∏≤‡∏á": "route_code",
    "‡∏™‡∏≤‡∏¢‡∏ó‡∏≤‡∏á": "route_name",
    # Accident details
    "‡∏£‡∏ñ‡∏Ñ‡∏±‡∏ô‡∏ó‡∏µ‡πà1": "vehicle_1",
    "‡∏ö‡∏£‡∏¥‡πÄ‡∏ß‡∏ì‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏": "accident_area_type",
    "‡∏°‡∏π‡∏•‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏±‡∏ô‡∏ô‡∏¥‡∏©‡∏ê‡∏≤‡∏ô": "presumed_cause",
    "‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏": "accident_type",
    "‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®": "weather_condition",
    # Vehicles
    "‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏": "total_vehicles",
    "‡∏£‡∏ñ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏": "total_vehicles_and_people",
    "‡∏£‡∏ñ‡∏à‡∏±‡∏Å‡∏£‡∏¢‡∏≤‡∏ô‡∏¢‡∏ô‡∏ï‡πå": "motorcycles",
    "‡∏£‡∏ñ‡∏™‡∏≤‡∏°‡∏•‡πâ‡∏≠‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á": "tricycles",
    "‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå‡∏ô‡∏±‡πà‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•": "private_cars",
    "‡∏£‡∏ñ‡∏ï‡∏π‡πâ": "vans",
    "‡∏£‡∏ñ‡∏õ‡∏¥‡∏Ñ‡∏≠‡∏±‡∏û‡πÇ‡∏î‡∏¢‡∏™‡∏≤‡∏£": "passenger_pickups",
    "‡∏£‡∏ñ‡πÇ‡∏î‡∏¢‡∏™‡∏≤‡∏£‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤4‡∏•‡πâ‡∏≠": "buses",
    "‡∏£‡∏ñ‡∏õ‡∏¥‡∏Ñ‡∏≠‡∏±‡∏û‡∏ö‡∏£‡∏£‡∏ó‡∏∏‡∏Å4‡∏•‡πâ‡∏≠": "pickup_trucks_4wheel",
    "‡∏£‡∏ñ‡∏ö‡∏£‡∏£‡∏ó‡∏∏‡∏Å6‡∏•‡πâ‡∏≠": "trucks_6wheel",
    "‡∏£‡∏ñ‡∏ö‡∏£‡∏£‡∏ó‡∏∏‡∏Å‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô10‡∏•‡πâ‡∏≠": "trucks_under_10wheel",
    "‡∏£‡∏ñ‡∏ö‡∏£‡∏£‡∏ó‡∏∏‡∏Å‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤10‡∏•‡πâ‡∏≠": "trucks_over_10wheel",
    "‡∏£‡∏ñ‡∏≠‡∏µ‡πÅ‡∏ï‡πã‡∏ô": "tuk_tuks",
    "‡∏£‡∏ñ‡∏≠‡∏∑‡πà‡∏ô‡πÜ": "other_vehicles",
    "‡∏Ñ‡∏ô‡πÄ‡∏î‡∏¥‡∏ô‡πÄ‡∏ó‡πâ‡∏≤": "pedestrians",
    # Casualties
    "‡∏ú‡∏π‡πâ‡πÄ‡∏™‡∏µ‡∏¢‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï": "casualties_fatal",
    "‡∏ú‡∏π‡πâ‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡∏™‡∏≤‡∏´‡∏±‡∏™": "casualties_serious",
    "‡∏ú‡∏π‡πâ‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢": "casualties_minor",
    "‡∏£‡∏ß‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏π‡πâ‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö": "casualties_total",
    # Weather
    "temperature": "temperature",
    "dewpoint": "dewpoint",
    "humidity": "humidity",
    "wind_speed": "wind_speed",
    "wind_direction": "wind_direction",
    "pressure": "pressure",
    "cloud_cover": "cloud_cover",
}

# Rename columns
df_renamed = df.rename(columns=column_mapping)
print(f"‚úÖ Mapped {len([k for k in column_mapping if k in df.columns])} columns")

# Select only columns that exist in both CSV and Supabase schema
supabase_columns = [
    "acc_code",
    "accident_year",
    "accident_date",
    "accident_time",
    "accident_datetime",
    "report_date",
    "report_time",
    "hour",
    "latitude",
    "longitude",
    "province",
    "km",
    "accident_location",
    "organization",
    "organization_route",
    "route_code",
    "route_name",
    "vehicle_1",
    "accident_area_type",
    "presumed_cause",
    "accident_type",
    "weather_condition",
    "total_vehicles",
    "total_vehicles_and_people",
    "motorcycles",
    "tricycles",
    "private_cars",
    "vans",
    "passenger_pickups",
    "buses",
    "pickup_trucks_4wheel",
    "trucks_6wheel",
    "trucks_under_10wheel",
    "trucks_over_10wheel",
    "tuk_tuks",
    "other_vehicles",
    "pedestrians",
    "casualties_fatal",
    "casualties_serious",
    "casualties_minor",
    "casualties_total",
    "temperature",
    "dewpoint",
    "humidity",
    "wind_speed",
    "wind_direction",
    "pressure",
    "cloud_cover",
]

available_cols = [col for col in supabase_columns if col in df_renamed.columns]
df_upload = df_renamed[available_cols].copy()

print(f"   Selected {len(available_cols)} columns for upload")

# Handle data types and missing values
print("\nüîß Cleaning data...")

# Numeric columns - convert to int
int_cols = [
    "accident_year",
    "hour",
    "total_vehicles",
    "total_vehicles_and_people",
    "motorcycles",
    "tricycles",
    "private_cars",
    "vans",
    "passenger_pickups",
    "buses",
    "pickup_trucks_4wheel",
    "trucks_6wheel",
    "trucks_under_10wheel",
    "trucks_over_10wheel",
    "tuk_tuks",
    "other_vehicles",
    "pedestrians",
    "casualties_fatal",
    "casualties_serious",
    "casualties_minor",
    "casualties_total",
]

for col in int_cols:
    if col in df_upload.columns:
        df_upload[col] = (
            pd.to_numeric(df_upload[col], errors="coerce").fillna(0).astype(int)
        )

# Float columns
float_cols = [
    "latitude",
    "longitude",
    "km",
    "temperature",
    "dewpoint",
    "humidity",
    "wind_speed",
    "wind_direction",
    "pressure",
    "cloud_cover",
]

for col in float_cols:
    if col in df_upload.columns:
        df_upload[col] = (
            pd.to_numeric(df_upload[col], errors="coerce").fillna(0.0).astype(float)
        )

# Replace NaN with None for database NULL
df_upload = df_upload.where(pd.notna(df_upload), None)

# Convert to records
records = df_upload.to_dict("records")
print(f"‚úÖ Prepared {len(records):,} records")
print(f"   Sample: {list(records[0].keys())[:10]}...")

# Connect to Supabase
print("\nüì° Connecting to Supabase...")
client = get_supabase_traffic_client()

# Upload in batches
print(f"\nüì§ Uploading {len(records):,} records to Supabase...")
print("   Batch size: 1000 records")
print("   Estimated time: 10-15 minutes")
print("")

batch_size = 1000
total_uploaded = 0
failed_batches = 0
start_time = datetime.now()

for i in range(0, len(records), batch_size):
    batch = records[i : i + batch_size]
    batch_num = (i // batch_size) + 1
    total_batches = (len(records) + batch_size - 1) // batch_size

    try:
        response = client.client.table("accident_records").insert(batch).execute()
        total_uploaded += len(batch)

        # Calculate progress
        progress = (total_uploaded / len(records)) * 100
        elapsed = (datetime.now() - start_time).total_seconds()
        speed = total_uploaded / elapsed if elapsed > 0 else 0
        eta = (len(records) - total_uploaded) / speed if speed > 0 else 0

        print(
            f"   [{batch_num:3d}/{total_batches}] ‚úÖ {total_uploaded:6,}/{len(records):,} "
            f"({progress:5.1f}%) | {speed:4.0f} rec/s | ETA: {int(eta / 60):2d}m{int(eta % 60):02d}s"
        )

    except Exception as e:
        failed_batches += 1
        error_msg = str(e)[:100]
        print(f"   [{batch_num:3d}/{total_batches}] ‚ùå Error: {error_msg}")

        if failed_batches >= 10:
            print(f"\n‚ùå Too many errors ({failed_batches}). Stopping.")
            break

elapsed_total = (datetime.now() - start_time).total_seconds()

# Verify upload
print(f"\nüìä Verifying upload...")
try:
    response = (
        client.client.table("accident_records")
        .select("*", count="exact")
        .limit(0)
        .execute()
    )
    final_count = response.count

    print(f"\n{'=' * 80}")
    print(f"‚úÖ UPLOAD COMPLETE!")
    print(f"{'=' * 80}")
    print(f"   üìä Records in Supabase: {final_count:,}")
    print(f"   üìã Expected total: {len(records):,}")
    print(f"   ‚è±Ô∏è  Upload time: {int(elapsed_total / 60)}m {int(elapsed_total % 60)}s")
    print(f"   ‚ö° Upload speed: {total_uploaded / elapsed_total:.0f} records/second")
    print(f"   ‚ùå Failed batches: {failed_batches}")

    if final_count == len(records):
        print(f"\nüéâ SUCCESS! All {final_count:,} records uploaded!")
    elif final_count > 0:
        missing = len(records) - final_count
        print(f"\n‚ö†Ô∏è  Partial upload: Missing {missing:,} records")
    else:
        print(f"\n‚ùå FAILED: No records uploaded")

except Exception as e:
    print(f"‚ùå Error verifying: {e}")

print(f"\n{'=' * 80}")
